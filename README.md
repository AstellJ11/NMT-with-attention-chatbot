# NMT With Attention Language Model

A sequence-to-sequence (seq2seq) model created for basic text-based interaction. Roughly based on 'Effective Approaches to Attention-based Neural Machine Translation' (Luong et al., 2015).

Snippets of code taken from: https://www.tensorflow.org/text/tutorials/nmt_with_attention
